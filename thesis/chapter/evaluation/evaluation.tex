\chapter{Evaluation}
In der Evaluation werden drei Aspekte betrachtet: Klassifizierungsgenauigkeit, Robustheit und Resourcennutzung.
Bei der Klassifizierungsgenauigkeit wird einerseits die Standorterkennung und andererseits die Anomalieerkennung evaluiert.
Dabei wird sowohl auf verschiedene Größen von FFNN und Entscheidungswälder eingegangen,
als auch auf verschieden viele zu unterscheidenden Standorte.
\newline
\newline
Bei der Robustheit wird auf den Fehler des besten FFNN und Entscheidungswald bei verschiedene Fehlerszenarien eingegangen.
Diese bestehen aus fehlerhafte Sensordaten durch Rauschen oder ausgefallenen Sensoren,
Routen mit permutierten Teilstücken und Routen, bei denen simuliert wird, dass der letzte Standort übersprungen wurde.
\newline
\newline
Bei der Resourcennutzung wird auf die Programmgröße und die Ausführungszeit der besten ML-Modelle eingegangen.
Außderdem wird der Energieverbrauch für verschiedene Szenarien eingeschätzt.
\newline
\newline
Unterschieden werden zwei Varianten der Testmengen.
Diese unterscheiden sich in der Art, wie der die Features für den vorherigen Standort bestimmt werden.
In der ersten Variante sind alle vorherigen Standorte korrekt.
In der zweiten Variante ist der erste vorherige Standort 0 und alle folgenden vorherigen Standorte werden iterativ durch das ML-Modell bestimmt,
d.~h. in dieser Variante wird der propagierte Fehler durch die Rückwärtskante des ML-Modells betrachtet.

\input{chapter/evaluation/metrics}
\input{chapter/evaluation/accuracy}
\input{chapter/evaluation/anomaly_detection}

\section{Signifikanz der Features}
\begin{itemize}
    \item Signifikanz der Features
    \item Einfluss von einzelnen Features für die Klassifizierungsgenauigkeit(?) => Last Distinct location möglicherweise schlecht, da die eigentliche Last Distinct Location oft durch fehlende Interrupts übersprungen wird
    \item Welche Feature werden genutzt? => Abhängig von Feature Importance und wie günstig zu berechnen
    \item Ist es sinnvoll für jeden Ort ein Feature zu haben, dass auf eins gesetzt wird, wenn der Ort erkannt wurde und ansonsten exponentiell abfällt. Wie schnell sollte es fallen, wenn ja?
\end{itemize}

\section{Benötigte Anzahl der Trainingsdaten}
\begin{itemize}
    \item Werden mehr Trainingsdaten benötigt mit steigender Ort Anzahl? Wenn ja wie viel? (Hier oder bei ML-Modell Training)
    \item Wie viele Trainingsdaten werden benötigt?
    \begin{itemize}
        \item Um KNN zu trainieren?
        \item Um Entscheidungsbaum zu trainieren?
        \item Ggf. Unterschiede klären
        \item (Gehört das schon in eine Evaluation, oder ist das hier okay?)
    \end{itemize}
\end{itemize}

\input{chapter/evaluation/robustness}
\input{chapter/evaluation/resource_usage}

\begin{table}[h!]
    \hspace{-1.5cm}
    \begin{tabular}{ | c | c | c | c | c | c | c | c | c | c | }
        \hline
        \multicolumn{2}{ | l |}{acc / Standorte } & 9 & 16 & 17 & 25 & 32 & 48 & 52 & 102 \\\hline
        \multicolumn{10}{| l |}{\textbf{Entscheidungswälder}}\\\hline
        Waldgröße & Max. Baumgröße & \multicolumn{8}{ c |}{}\\\hline
        16 & 8 & 98.65\% & 97.33\% & 97.96\% & 97.21\% & 95.85\% & 91.37\% & 94.31\% & 86.13\% \\\hline
        16 & 16 & 98.77\% & 98.78\% & 98.54\% & 98.23\% & 98.04\% & 96.98\% & 98.00\% & 96.17\% \\\hline
        16 & 32 & 98.72\% & 98.63\% & 98.46\% & 98.29\% & 97.57\% & 97.32\% & 98.07\% & 96.26\% \\\hline
        16 & 64 & 98.72\% & 98.63\% & 98.46\% & 98.31\% & 97.57\% & 97.32\% & 97.98\% & 96.26\% \\\hline
        8 & 32 & 98.58\% & 98.19\% & 98.40\% & 98.30\% & 97.35\% & 96.78\% & 98.00\% & 95.90\% \\\hline
        16 & 32 & 98.72\% & 98.63\% & 98.46\% & 98.29\% & 97.57\% & 97.32\% & 98.07\% & 96.26\% \\\hline
        32 & 32 & 98.82\% & 98.91\% & 98.60\% & 98.43\% & 98.32\% & 97.51\% & 98.11\% & 96.50\% \\\hline
        64 & 32 & 98.70\% & 98.91\% & 98.56\% & 98.46\% & 98.17\% & 97.78\% & 98.23\% & 96.61\% \\\hline
        32 & 64 & 98.82\% & 98.91\% & 98.60\% & 98.43\% & 98.32\% & 97.51\% & 98.11\% & 96.42\% \\\hline
        \multicolumn{10}{| l |}{\textbf{Feed Forward neuronale Netzwerke}}\\\hline
        \#Schichten & \#Neuronen & \multicolumn{8}{ c |}{}\\\hline
        1 & 16 & 97.86\% & 97.05\% & 96.47\% & 97.27\% & 92.99\% & 90.83\% & 95.66\% & 87.51\% \\\hline
        1 & 32 & 98.21\% & 98.07\% & 97.15\% & 97.24\% & 94.21\% & 93.26\% & 96.92\% & 89.69\% \\\hline
        1 & 64 & 98.12\% & 98.05\% & 97.72\% & 97.85\% & 95.09\% & 94.39\% & 96.38\% & 90.57\% \\\hline
        1 & 128 & 98.22\% & 98.79\% & 97.77\% & 97.78\% & 96.71\% & 94.81\% & 97.52\% & 92.22\% \\\hline
        2 & 32 & 97.78\% & 97.81\% & 97.53\% & 98.06\% & 96.17\% & 94.24\% & 97.08\% & 91.70\% \\\hline
        4 & 32 & 98.08\% & 97.70\% & 97.54\% & 98.10\% & 95.51\% & 95.26\% & 97.02\% & 91.84\% \\\hline
        8 & 32 & 98.14\% & 95.97\% & 97.48\% & 97.99\% & 95.65\% & 94.47\% & 97.73\% & 94.41\% \\\hline
        4 & 64 & 98.33\% & 97.51\% & 97.78\% & 97.96\% & 94.18\% & 96.55\% & 97.54\% & 91.60\% \\\hline
    \end{tabular}
    \caption{TODO: Caption}
    \label{tab:TODO_LABEL}
\end{table}
