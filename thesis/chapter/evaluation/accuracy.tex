\section{Klassifizierungsgenauigkeit}
TODO
\subsection{Metriken}
In dieser Arbeit werden verschiedene Metriken zur Ermittlung der Klassifizierungsgenauigkeit ermittelt.
Zunächst die übliche Klassifizierungsgenauigkeit (\ref{formular:simple_accuracy}), in der die Anzahl der korrekt klassifizierten Standorte mit der Gesamtanzahl verglichen werden.
\begin{align}
    \label{formular:simple_accuracy}
    P(A) := \frac{\text{Anzahl korrekter Klassifizierungen}}{\text{Gesamtanzahl}}
\end{align}
Die zweite Metrik (\ref{formular:accuracy_metrik2}) betrachtet die Klassifizierungsgenauigkeit unter Tolerierung, dass ein Standort
fünf bzw. zehn Klassifizierungen kontinuierlich zu früh oder zu spät verlassen wurde,
d.~h. Fehlklassifizierungen werden vernachlässigt, wenn kontinuierlich der letzte korrekte Standort bzw. der nächste korrekte
Standort klassifiziert wird mit einer Gesamttoleranz von fünf bzw. zehn Klassifizierungen.
\begin{flalign}
    \label{formular:accuracy_metrik2}
&\epsilon \in \{5, 10\} \nonumber\\
&L := \text{Menge von dem ML-Modell klassifizierten Standorte.} \nonumber\\
&K := \text{Menge von den wirklichen Standorten.} \nonumber\\
&\Phi(i) := \text{Index von dem nächsten Standort.} \nonumber\\
&\Psi(i) := \text{Index von dem vorherigen Standort.} \nonumber\\
&\Omega(i) := \Phi(i)-i\leq\epsilon\wedge\hspace{-0.3cm} \bigwedge\limits_{i\leq q \leq \min(\#K, \Phi(i))}\hspace{-0.3cm} L_q=K_{\Phi(i)} \nonumber\\
&\Theta(i) := i-\Psi(i)\leq\epsilon\wedge\hspace{-0.3cm} \bigwedge\limits_{\max(0, \Psi(i))\leq q \leq i}\hspace{-0.3cm} L_q=K_{\Psi(i)} \nonumber\\
&P(B) := \frac{\#\{L_i | L_i=K_i \vee \Omega(i) \vee \Theta(i)\text{ für } i\in\{0, 1, ..., \#L - 1\}\}}{\#K}
\end{flalign}
Die Testmenge existiert in zwei Varianten, die sich durch die Bestimmung des vorherigen Standortes in den beinhalteten Feature-Mengen unterscheidet.
In der ersten Variante sind alle vorherigen Standorte korrekt.
In der zweiten Variante ist der erste vorherige Standort 0 und alle folgenden vorherigen Standorte werden iterativ durch das ML-Modell bestimmt,
d.~h. in dieser Variante wird der propagierte Fehler durch die Rückwärtskante des ML-Modells betrachtet.
\newline
\newline
Für die zweite Variante sind zwei weitere Metriken relevant.
Bei diesen Metriken wird die Klassifizierungsgenauigkeit bestimmt, unter der Bedingung, dass der vorherige
Standort korrekt (\ref{formular:accuracy_previous_was_correct}) bzw. falsch (\ref{formular:accuracy_previous_was_wrong}) war.
\begin{align}
    \label{formular:accuracy_previous_was_correct}
    P(C) := \frac{\text{Anzahl korrekter Klassifizierungen, wenn vorheriger Standort korrekt war}}{\text{Alle Klassifizierungen, wenn vorheriger Standort korrekt war}}
\end{align}
\begin{align}
    \label{formular:accuracy_previous_was_wrong}
    P(D) := \frac{\text{Anzahl korrekter Klassifizierungen, wenn vorheriger Standort falsch war}}{\text{Alle Klassifizierungen, wenn vorheriger Standort falsch war}}
\end{align}

\begin{itemize}
    \item Wie groß ist die Wahrscheinlichkeit, dass die Orte korrekt erkannt werden?
    \item Entscheidungsbaum vs KNN
    \item Skalierung mit Anzahl der Orte
    \item Signifikanz der Features
    \item Einfluss von einzelnen Features für die Klassifizierungsgenauigkeit(?) => Last Distinct location möglicherweise schlecht, da die eigentliche Last Distinct Location oft durch fehlende Interrupts übersprungen wird
    \item Welche Feature werden genutzt? => Abhängig von Feature Importance und wie günstig zu berechnen
    \item Ist es sinnvoll für jeden Ort ein Feature zu haben, dass auf eins gesetzt wird, wenn der Ort erkannt wurde und ansonsten exponentiell abfällt. Wie schnell sollte es fallen, wenn ja?
    \item Werden mehr Trainingsdaten benötigt mit steigender Ort Anzahl? Wenn ja wie viel? (Hier oder bei ML-Modell Training)
    \item Irgendwo drüber reden wie wir evaluieren, also continued predict vs predict und die ganzen Testsets
    \item Wie viele Trainingsdaten werden benötigt?
    \begin{itemize}
        \item Um KNN zu trainieren?
        \item Um Entscheidungsbaum zu trainieren?
        \item Ggf. Unterschiede klären
        \item (Gehört das schon in eine Evaluation, oder ist das hier okay?)
    \end{itemize}
\end{itemize}