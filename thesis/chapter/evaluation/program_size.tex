\section{Programmspeicher}
Der Großteil des Programmspeichers wird für das ML-Modell benötigt.
Aus diesem Grund wird der Anteil des Programmspeichers in der Evaluation vernachlässigt,
der für die restlichen Funktionen und für die Feature-Extrahierung benötigt wird.
Zudem ist der benötigte Programmspeicher dieses Anteils konstant und skaliert nicht mit der Größe, wie die ML-Modelle.
\newpage
Zur Einschätzung des Programmspeichers der Entscheidungsbäume wird der hybride Ansatz mit einer Toleranz von $\epsilon=0$ angenommen,
d. h. es werden für eindeutige Ergebnisse diskrete Rückgaben zurückgegeben, anstatt der Wahrscheinlichkeitsverteilung.
Als Datentyp für die Vergleiche und allen Features wird angenommen, dass ein vier Byte Datentyp verwendet wird.
Für einen Vergleich werden fünf Instruktionen benötigt \cite{dymelThesis}.
Für eine Rückgabe werden zwischen zwei und $2(N+1)$ Instruktionen und zwischen 0 und $2N$ Parameter benötigt,
wobei $N$ die Anzahl der möglichen Standorte ist.
Die Größe einer Instruktion ist vier Byte, da eine 32-Bit CPU angenommen wird.
Die Größe des Algorithmus des zusammenfassenden Klassifizierers wird vernachlässigt.
\newline
\newline
Für die FFNNs wird ebenfalls ein vier Byte Datentyp für die Biase und die Gewichte angenommen.
Die Größe des Algorithmus zur Ausführung des FFNNs ist unbekannt und wird als konstanter Wert angenommen,
liegt aber, den Zahlen in Gieses Arbeit nach zu urteilen, zwischen 6 KB und 7 KB \cite{gieseThesis}.
Diese Messungen beziehen sich aber auf einen 8-Bit Mikrocontroller, weshalb dieser Anteil für ein 32-Bit Mikrocontroller möglicherweise größer ist.
\newline
\newline
Tabelle \ref{tab:predictions_by_loc_size} zeigt Einschätzungen des benötigten Programmspeichers der verschiedenen Konfigurationen der ML-Modelle,
wobei die konstanten Anteile vernachlässigt werden.
Potentielle Optimierungen der Entscheidungswälder, z. B. durch den Compiler,
sowie potentielle Optimierungen des FFNNs, wie Giese in \cite{gieseThesis} vorgeschlagen hat, wurden dabei nicht betrachtet.
Giese hat mit dem CSC-MA-Bit Format die Programmgröße um 39\% reduzieren können.
Kompilierung mit der Optimierungsstufe \textit{O2} konnte experimentell generierten C-Code
eines Entscheidungswaldes um bis zu 21,3\% reduzieren.
\begin{table}[h!]
    \hspace{-2cm}
    \begin{tabular}{ | c | c | c | c | c | c | c | c | c | c | }
        \hline
        \multicolumn{2}{ | l |}{Programmgröße in KB über Standorte} & 9 & 16 & 17 & 25 & 32 & 48 & 52 & 102 \\\hline
        \multicolumn{10}{| l |}{\textbf{Entscheidungswälder}}\\\hline
        Waldgröße & Max. Baumgröße & \multicolumn{8}{ c |}{}\\\hline
        16 & 8 & 72.2 & 71.2 & 119.8 & 157.5 & 132.8 & 184.3 & 237.9 & 316.3 \\\hline
        16 & 16 & 158.2 & 114.5 & 264.9 & 465.0 & 297.0 & 573.7 & 724.7 & 1063.2 \\\hline
        16 & 32 & 158.8 & 132.5 & 277.8 & 472.2 & 293.4 & 625.9 & 771.2 & 1147.8 \\\hline
        16 & 64 & 158.8 & 132.5 & 277.8 & 472.2 & 293.4 & 625.9 & 771.2 & 1147.8 \\\hline
        8 & 32 & 72.2 & 68.4 & 135.4 & 242.1 & 144.4 & 317.2 & 415.2 & 578.4 \\\hline
        32 & 32 & 325.9 & 250.7 & 550.8 & 951.2 & 576.1 & 1151.9 & 1676.2 & 2294.5 \\\hline
        64 & 32 & 669.2 & 522.8 & 1107.6 & 1906.5 & 1141.4 & 2440.0 & 3244.9 & 4673.7 \\\hline
        32 & 64 & 325.9 & 250.7 & 550.8 & 951.2 & 576.1 & 1151.9 & 1676.2 & 2294.5 \\\hline
        \multicolumn{10}{| l |}{\textbf{Feed Forward neuronale Netzwerke}}\\\hline
        \#Schichten & \#Neuronen & \multicolumn{8}{ c |}{}\\\hline
        1 & 16 & 2.8 & 3.2 & 3.3 & 3.8 & 4.2 & 5.2 & 5.5 & 8.7 \\\hline
        1 & 32 & 5.5 & 6.4 & 6.5 & 7.6 & 8.4 & 10.5 & 11.0 & 17.4 \\\hline
        1 & 64 & 11.0 & 12.8 & 13.1 & 15.1 & 16.9 & 21.0 & 22.0 & 34.8 \\\hline
        1 & 128 & 22.0 & 25.6 & 26.1 & 30.2 & 33.8 & 42.0 & 44.0 & 69.6 \\\hline
        2 & 32 & 9.6 & 10.5 & 10.6 & 11.6 & 12.5 & 14.6 & 15.1 & 21.5 \\\hline
        4 & 32 & 17.8 & 18.7 & 18.8 & 19.8 & 20.7 & 22.8 & 23.3 & 29.7 \\\hline
        8 & 32 & 34.2 & 35.1 & 35.2 & 36.2 & 37.1 & 39.2 & 39.7 & 46.1 \\\hline
        4 & 64 & 60.2 & 62.0 & 62.2 & 64.3 & 66.0 & 70.1 & 71.2 & 84.0 \\\hline
    \end{tabular}
    \caption{Programmgröße in KB über Standorte und Konfigurationen der ML-Modelle.}
    \label{tab:predictions_by_loc_size}
\end{table}
\newline
\newline
Der benötigte Programmspeicher beider ML-Modelle skaliert mit der Standortkomplexität, der Anzahl der verdeckten Schichten bzw. der Waldgröße
und der Anzahl der Neuronen pro verdeckte Schicht bzw. der maximalen Baumhöhe.
Für Entscheidungswälder werden maximal ca. 4,7 MB benötigt.
Der beste Entscheidungswald bei einer Standortkomplexität von 102 benötigt aber nur ca. 1,1 MB.
Die FFNNs hingegen benötigen deutlich weniger Programmspeicher.
Für beide ML-Modelle gibt es Mikrocontroller, die ausreichend Programmspeicher anbieten.
Im Vergleich zu dem WFFNN und WFBNN von Mian sind die FFNNs dieser Arbeit zwischen 54\% und 97,6\% kleiner bei ähnlicher Standortkomplexität.
Die Entscheidungswälder können bis zu 47\% kleiner sein, aber auch bis zu 720\% größer sein.