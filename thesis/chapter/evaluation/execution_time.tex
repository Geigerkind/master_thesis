\section{Ausführungszeit und benötigte Energie}
Es ist problemetisch eine sinvolle Estimierung für die benötigte Ausführungszeit und Energie anzugeben, da
die Ausführungszeit und die benötigte Energie abhängig von dem verwendeten Mikrocontroller sind.
Vergleichbare 32-Bit Mikrocontroller mit FPU (Floating Point Unit), zu den Microcontrollern die Dymel verwendet hat \cite{dymelThesis}, sind aus der AVR C-Serie \cite{avr32BitDatasheet}.
Leider ist aus deren Datenblätter keine Information über die Ausführungszeit von Gleitkommazahlinstruktionen und kein Energiemodell zu entnehmen.
Es ist aber anzunehmen, dass deutlich weniger Cyclen benötigt werden für hardwareunterstützte Gleitkommazahloperationen, als Software basierte Alternativen.
Aus diesem Grund wird die Ausführungszeit in Gleitkommazahl- Vergleichen, Multiplikationen, Division, Additionen und Wurzel angegeben,
da diese die integralen Bestandteile der Feature-Extrahierung und Evaluation der ML-Modelle sind.
\newline
\newline
Die in dieser Arbeit vorgeschlagene Architektur (\ref{fig:model_idea}) hat fünf Bestandteile, die jeweils zur Gesamtausführungszeit beitragen.
Die Aufnahme der Sensorwerte wird als konstanter Energieverbrauch angenommen und in dieser Rechnung vernachlässigt.
In der ersten Feature-Extrahierung werden 34 Features aus dem Datenfenster extrahiert.
Tabelle \ref{tab:feature_operation_complexity} zeigt die estimierte Anzahl der Operationen, die pro Art des Features benötigt werden.
\begin{table}[h!]
    \centering
    \begin{tabular}{ | l | c | c | c | c | c | }
        \hline
        Art des Features & Vergleich & Multiplikation & Division & Addition & Wurzel \\\hline
        Standardabweichung (\textbf{7}) & 0 & 3 & 2 & 7 & 1 \\\hline
        Minimum (\textbf{6}) / Maximum (\textbf{6}) & 2 & 0 & 0 & 0 & 0 \\\hline
        Durchschnitt (\textbf{6}) & 0 & 0 & 1 & 2 & 0 \\\hline
        Wert (\textbf{9}) & 0 & 0 & 0 & 0 & 0 \\\hline
    \end{tabular}
    \caption{Estimierte Anzahl der Operationen pro Art des Features bei einer Datenfenstergröße von 3. Fettgedruckte Zahl zeigt die Verwendungsanazahl in der Feature-Menge an.}
    \label{tab:feature_operation_complexity}
\end{table}
\newline
\newline
Zur Evaluierung eines Entscheidungsbaumes werden höchstens $Q\leq\text{Waldgröße}\ \cdot\ \text{Max. Baumhöhe}$ Vergleiche benötigt,
sowie $R\leq\text{Waldgröße}\ \cdot\ \text{\#Standorte}$ Additionen und \text{\#Standorte} zusätzliche Vergleiche, um die einzelnen Entscheidungsbäume zusammenzufassen \cite{dymelThesis}.
Für einen Entscheidungswald mit 8 Bäumen mit einer maximalen Höhe von 16 und 102 Standorten werden damit 230 Vergleiche und 816 Additionen benötigt.
\newline
\newline
Für die Evaluierung eines FFNNs mit der in Kapitel \ref{sec:model_ffnn} beschriebenen Struktur setzen sich die benötigten Operationen folgendermaßen zusammen.
Die Größe der ersten Schicht des FFNNs ist $n_1:=\text{\#Features}$.
Die Größe der letzten Schicht ist $n_m:=\text{\#Standorte}$.
Dazwischen liegen $m-2$ Schichten, die jeweils $K$ Neuronen haben.
Bei jeder Schicht $i$ werden für jedes Neuron in $n_{i+1}$, $n_i$ Multiplikationen und $n_i$ Additionen, sowie ein Vergleich für die Aktivierungsfunktion ReLU verwendet.
Für die SoftMax-Funktion in der letzten Schicht müssen $n_m$ Divisionen durchgeführt werden, $n_m$ Additionen, sowie $n_m$ die $\exp$-Funktion ausgeführt werden.
Insgesamt werden für die Ausführung eines FFNNs mit einer verdeckten Schicht mit 32 Neuronen,
bei 102 Standorten, 4352 Multiplikationen, 4454 Additionen, 134 Vergleiche, 102 Divisionen und 102 $\exp$-Funktionen benötigt.
\newline
\newline
Bei der Feature-Extrahierung für das ML-Modell zur Anomalieerkennung werden nur vier Features extrahiert.
Tabelle \ref{tab:anomaly_feature_operation_complexity} zeigt die estimierte Anzahl der Operationen, die für die einzelnen Features benötigt werden.
Der Entscheidungswald zur Anomalieerkennung besteht aus 4 Entscheidungsbäumen mit einer maximalen Baumhöhe von 8.
Das FFNN zur Anomalieerkennung hat eine verdeckte Schicht mit 16 Neuronen und die Ausgabeschicht hat nur ein Neuron.
Der Entscheidungswald benötigt damit 34 Vergleiche und 8 Additionen.
Das FFNN benötigt 80 Multiplikationen, 81 Additionen, 17 Vergleiche, eine Division und eine $\exp$-Funktion.
\begin{table}[h!]
    \centering
    \begin{tabular}{ | p{4.5cm} | c | c | c | c | c | }
        \hline
        Feature & Vergleich & Multiplikation & Division & Addition & Wurzel \\\hline
        Abweichung zum ØStandortänderungen & 4 & 0 & 2 & 5 & 0 \\\hline
        Abweichung zum ØKlassifizierungswahrscheinlichkeit & 4 & 0 & 2 & 5 & 0 \\\hline
        Topologieverletzung & 5 & 1 & 0 & 1 & 0 \\\hline
        Standardabweichung Top 5 Klassifizierungen & 0 & 5 & 2 & 13 & 1 \\\hline
    \end{tabular}
    \caption{Estimierte Anzahl der Operationen pro Feature der Anomalieerkennung.}
    \label{tab:anomaly_feature_operation_complexity}
\end{table}
\newline
\newline
Tabelle \ref{tab:complexity_summary} fasst die Anzahl der Operationen für eine Konfiguration mit ausschließlich Entscheidungswäldern und FFNNs zusammen.
Es ist zu erwarten, dass die Entscheidungswälder weniger Ausführungszeit benötigen als die FFNNs, da deutlich weniger Operationen benötigt werden,
wodurch sich ein Entscheidungsbaum basierter Klassifizierer in Hinsicht auf die benötigte Energie besser eignet.
Bei konstanter Bewegung wurde in den Testszenarien der Mikrocontroller alle 166 ms aufgeweckt.
Dies ist aber unrealistisch, da die Sensorenbox auch für lange Zeit an einem Ort verbleiben kann, was sich positiv auf den Energiebedarf auswirkt.
\begin{table}[h!]
    \centering
    \begin{tabular}{ | l | c | c | }
        \hline
        Operation & Entscheidungswald & FFNN \\\hline
        Vergleich & 289 & 176 \\\hline
        Multiplikation & 27 & 4459 \\\hline
        Division & 26 & 129 \\\hline
        Addition & 909 & 5444 \\\hline
        Wurzel & 8 & 8 \\\hline
        $\exp$-Funktion & 0 & 103 \\\hline
    \end{tabular}
    \caption{Estimierte Anzahl der Operationen für die gesamte Ausführung mit den im Besipiel genannten Größen für Entscheidungswald und FFNN.}
    \label{tab:complexity_summary}
\end{table}