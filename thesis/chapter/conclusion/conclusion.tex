\chapter{Schlussfolgerungen}
Diese Arbeit hat gezeigt, dass Klassifizierer mit Entscheidungsbäumen sich besser als FFNNs zur Standorterkennung eignen.
Selbst bei hohen Standortkomplexitäten von 102 konnten Klassifizierungsgenauigkeiten $P(A)_{\text{cont}}$ von bis zu 84,37\% erreicht werden.
Anomalien konnten bis zu 52,58\% bei einer Fehlerrate von 2,95\% korrekt klassifiziert werden.
\newline
\newline
Die ML-Modelle sind klein genug für den Betrieb auf einem Mikrocontroller.
Es wurde gezeigt, dass ein Datenfenster von drei Einträgen ausreicht, um die Sensorwerte zu glätten und Features zu extrahieren.
Entscheidungswälder benötigen zwar mehr Programmspeicher, dafür aber weniger RAM und deutlich weniger Operationen als FFNNs, wodurch
ein geringerer Energieverbrauch zu erwarten ist.
\newline
\newline
Der Kodierungsansatz, der nur Knoten kodiert, skaliert besser als der Kodierungsansatz, der Kanten und Knoten kodiert.
Resultiere ML-Modelle haben bessere Klassifizierungsergebnisse mit ersteren Kodierungsansatz erzielt.
Entscheidungswälder skalieren mit steigender Standortkomplexität besser als FFNNs.
Mit jedem zusätzlichen Standort, ab einer Standortkomplexität von 9, verringert sich die Klassifizierungsgenauigkeit der Entscheidungswälder,
um 0,16\%, wohingegen sich die Klassifizierungsgenauigkeit bei FFNNs um 0,51\% verringert.
\newline
\newline
Die Signifikanz der Features ist abhängig von dem Einsatzszenario.
Die Permutationswichtigkeit hat sich als eine gute Methode erwiesen, um die Signifikanz einzelner Features einzuschätzen.
Zusätzlich hat sich gezeigt, dass die Nullung einzelner Features ebenfalls eine gute Methode zur Einschätzung der Signifikanz ist.
\newpage
Die ML-Modelle wurden mit fehlerhaften Daten trainiert, um die Fehlertoleranz zu erhöhen.
Es hat sich gezeigt, dass sowohl Entscheidungswälder als auch FFNNs robust gegenüber Abweichungen der Sensorwerte,
Ausfall von einzelnen Sensoren und Permutation der Routen ist.
Im Schnitt benötigt ein Entscheidungswald 5,2 Klassifizierungen, um den korrekten Standort wieder zu bestimmen,
nachdem es einen falschen Standort bestimmt hat.
Ein FFNN benötigt im Schnitt 5,8 Klassifizierungen.
\newline
\newline
Das Training mit einer Rückwärtskante ist sehr aufwändig und rechenintensiv.
Ohne die Rückwärtskante konnten vergleichbare bzw. teilweise bessere Klassifizierungsergebnisse erzielt werden.
Dabei ist das resultierende ML-Modell kleiner und unkomplizierter.
FFNNs konnten ohne Rückwärtskante bessere Klassifizierungsergbnisse erzielen.
\newline
\newline
Zukünftige Arbeiten sollten drei Bereiche weiter untersuchen.
Zunächst sollten diese ML-Modelle mit Echtdaten untersucht werden.
Dafür müsste ein Prototyp der Sensorenbox konstruiert werden und in
einem geeigneten Szenario ausreichend Daten aufgenommen werden.
Möglicherweise könnte ein Arduino Board mit handelsüblichen, vergleichbaren Sensoren ausreichen.
\newline
\newline
Weitere Optimierungen der ML-Modelle sollten untersucht werden.
Zunächst könnte die Anzahl der Features reduziert werden durch eine sorgfältige Auswahl mit Hilfe eines Optimierungsverfahrens.
Dort sollte die Klassifizierungsgenauigkeit und Ausführungszeit maximiert werden unter Einhaltung der Hardwarelimitierungen.
Zur Optimierung von KNN könnten die Ansätze von Giese aufgegriffen werden \cite{gieseThesis}.
\newline
\newline
Ein Energiemodell zur Einschätzung des Energieverbrauchs der verschiedenen ML-Modelle könnte erstellt werden.
Dieses könnte für verschiedene Batteriegrößen und Mikrocontroller, Einschätzungen für obere Schranken der Größe von
verschiedenen ML-Ansätzen angeben.
Damit können dann gezielter weitere Ansätze untersucht werden.