\chapter{Künstliche Neuronale Netze}
Das mathematische Modell von künstlichen neuronalen Netzen wurde von McCulloch und Pitts im Jahre 1943 erfunden \cite{mcculloch1943logical}.
Dieses Modell ist eine Abstraktion des biologischen Neuronen als logischer Mechanismus.
Man unterscheided beim biologischen Neuronen zwischen \textit{Afferent}-Neuronen, \textit{Efferent}-Neuronen und \textit{Inter}-Neuronen (TODO: Quelle).
Afferent-Neuronen nehmen elektrische Signale von Organen entgegen und können als \textit{Input} interpretiert werden.
Efferent-Neuronen geben elektrische Signale an \textit{Effektorzellen} weiter und können als \textit{Output} interpretiert werden.
Inter-Neuronen nehmen elektrische Signale von Afferent-Neuronen oder Inter-Neuronen entgegen und geben sie an Inter-Neuronen oder Efferent-Neuronen weiter.
Wenn der Schwellenwert eines \textit{Dendrite} von einem Neuronen durch ein elektrisches Signal erreicht wurde, wird ein elektrisches Signal über den \textit{Axon} an ein anderes Neuron oder Effektorzellen übertragen.
Diese Charakteristiken werden mathematisch als ein Vergleich von einer gewichtete Summe von eingehenden Signalen mit einem Schwellenwert modelliert (TODO: Quelle).
Gleichung \ref{formular:neuron_activation} stellt diesen Zusammenhang dar.
\begin{align}
    \label{formular:neuron_activation}
    y = a(\textbf{w}^\intercal\textbf{x} + b)
\end{align}
Die Vergleichsoperation ist die \textit{Aktivierungsfunktion} $a: \mathbb{R}\mapsto\mathbb{R}$, die in diesem Fall ist es die Stufenfunktion (TODO: Quelle).
Die Eingabe $\textbf{x}\in\mathbb{R}^n$ wird mit $\textbf{w}\in[0, 1]$ gewichtet und der \textit{Bias} $b\in\mathbb{R}$ wird addiert. Der Bias stellt den Schwellenwert dar.
\newline
\newline
Das künstliche neuronale Netz approximiert eine arbiträre Funktion $f^*$. Dazu findet es eine Menge von Parametern $\boldsymbol\theta$, wodurch $f^*(\textbf{x})\approx f(\textbf{x}, \boldsymbol\theta)$
möglichst gut von der Approximationsfunktion $f$ abgebildet wird.
\newline
\newline
Das KNN ist in Schichten organisiert. Analog zu den biologischen Neuron, gibt es eine \textit{Eingabeschicht (engl. Input-Layer)},
\textit{Ausgabeschicht (engl. Output-Layer)} und \textit{verdeckte Schicht (engl. Hidden-Layer)} (TODO: Quelle).
Analog zur Aktivierung eines einzelnen Neuronen, dargestellt in Gleichung \ref{formular:neuron_activation}, stellt Gleichung \ref{formular:layer_activation} die Aktivierung einer Schicht dar.
\begin{align}
    \label{formular:layer_activation}
    \textbf{a}_{i+1} = a_i(\textbf{z}_i), \hspace{2cm} \textbf{z}_i := \textbf{W}_i\textbf{a}_i + \textbf{b}_i
\end{align}
Das allgemeine KNN verfügt über $m\in\mathbb{N}$ Schichten. Jede Schicht $i$ verfügt über $n_i\in\mathbb{N}$ Neuronen.
Die Aktivierungsfunktion $a_i:\mathbb{R}^{n_{i+1}}\mapsto\mathbb{R}^{n_{i+1}}$ berechnet die Aktivierung mit der gewichteten Summe $\textbf{z}_i$.
Die gewichtete Summe setzt sich zusammen aus der Aktivierung der vorherigen Schicht $\textbf{a}_i$ die mit $W_i\in\mathbb{R}^{n_{i+1}x{n_{i}}}$ gewichtet wird.
Die Schwellenwerte jedes Neuronen werden durch die Biase $\textbf{b}_i\in\mathbb{R}^{n_{i+1}}$ dargestellt.
Gleichung \ref{formular:general_knn} zeigt, wie das allgemeine KNN mit einer rekursiven Funktion modelliert werden kann.
\begin{align}
    \label{formular:general_knn}
    \textbf{a}_1 := \textbf{x}, \hspace{1cm} \textbf{z}_i := \textbf{W}_i\textbf{a}_i + \textbf{b}_i, \hspace{1cm} \textbf{a}_{i+1} := a_i(\textbf{z}_i), \hspace{1cm} \textbf{f(x)} := \textbf{a}_m
\end{align}
Diese Arbeit nutzt ausschließelich \textit{Feed Forward neuronale Netzwerke}.
Diese werden durch \textit{dichte Schichten (engl. Dense-Layer)} charakterisiert, d. h. Schichten in denen alle Neuronen einer Schicht mit allen Neuronen der folgenden Schicht verbunden sind.

\section{Keras}
Keras ist die am meisten genutzte \textit{deep learning} API und wurde in Python geschrieben \cite{kerasDoc}.
Dadurch ist sie kompatibel mit allen gängigen Betriebssystemen.
Ihr Fokus ist eine intuitive und simple API anzubieten, sodass schnelle Iterationen im Entwicklungsprozess möglich sind.
Trotzdem ist sie effizient und skalierbar, um die Kapazitäten großer Rechenverbunde auszunutzen.
\newline
\newline
Keras abstrahiert das ML System \textit{Tensorflow}. Tensorflow implementiert ML Algorithmen, die dem Stand der Forschung entsprechen, mit dem Fokus
auf effizienten Training der Modelle \cite{abadi2016tensorflow}.
Dafür nutzt es die Multikernarchitektur von CPUs, GPUs und spezialisierte Hardware TPUs (\textbf{T}ensor \textbf{P}rocessing \textbf{U}nit).
Es wurde als open-source Projekt veröffentlicht und ist weit verbreitet.
\newline
\newline
Keras bietet die in dieser Arbeit benötigten Algorithmen an, weshalb sie zum Trainieren von FFNNs verwendet wird.

\section{Training von KNN}
\begin{itemize}
    \item Backpropagation von FFNN
    \item Gehe auch auf Verlust (loss) und Verlustfunktionen ein => Zusammenhang Optimierungsproblem
    \item Exploding/Vanishing Gradient Problem und wie es mit Aktivierungsfunktionen
\end{itemize}

\section{Optimierer}
Um die Zielfunktion zu approximieren ist eine Kostenfunktion nötig, die den Abstand von der approximierten Funktion zu der Zielfunktion angibt.
Diese Funktion wird als Verlustfunktion (engl. loss) bezeichnet und wird im Optimierungsprozess genutzt.
Üblicherweise wird Kreuzentropie verwendet, da sich diese experimentell als Beste erwiesen hat.
\newline
\newline
Die Strategie im Optimierungsprozess wird als Optimierer bezeichnet.
Diese Algorithmen steuern, wie die Parameter $\boldsymbol\theta$ aktualisiert werden.
Üblicherweise wird \textit{ADAM} verwendet.
ADAM ist eine Kombination aus \textit{SGD} (\textbf{S}tochastic \textbf{G}radient \textbf{D}escent) mit Momentum und \textit{RMSprop}.
\newline
\newline
SGD ist eine Approximation von \textit{Gradient Descent} (GD), oder \textit{Steepest Descent}.
GD ist ein iterativer Algorithmus, der den Gradienten in Richtung des Extrema folgt und dementsprechend die Eingabeparameter aktualisiert.
\begin{align}
    \label{formular:gradient_descent}
    x_{k+1} := \begin{cases}
                   x_k - f^{\prime}(x_k)\alpha_k & \text{, wenn} f(x_k - f^{\prime}(x_k)\eta_k) < f(x_k)\\
                   (1 + \alpha_k)x_k & \text{, ansonsten}
    \end{cases}
\end{align}
Gleichung \ref{formular:gradient_descent} illustriert diesen iterativen Prozess für Minimierung im eindimensionalen Fall,
wobei $\eta_k > 0$ eine angemessene \textit{Lernrate} ist.
Ist die Lernrate zu groß könnte keine Verbesserung beobachtet werden, da das Maxima immer übersprungen wird.
Ist die Lernrate zu klein könnte die Konvergenz sehr langsam sein.
Im mehrdimensionalen Fall wird für jede Komponente des Eingabevektors dieser Prozess durchgeführt, sodass für jede Komponente
die Richtung des Extrema verfolgt wird.
Dies impliziert, dass GD sehr aufwendig zu berechnen ist für Eingabevektoren mit hohen Dimensionen.
\begin{align}
    \label{formular:gd_multi_dim}
    \textbf{x}_{k+1} = \textbf{x}_k - \bigtriangledown f(\textbf{x}_k)\eta_k
\end{align}
Gleichung \ref{formular:gd_multi_dim} zeigt die iterative Berechnung im mehrdimensionalen Fall.
Zur Berechnung muss der Gradient des Eingabevektors berechnet werden.
Je größer die Dimension des Eingabevektor ist, desto aufwendiger ist die Berechnung.
\newline
\newline
SGD nimmt an, dass eine Verbesserung wahrscheinlich ist, wenn eine Komponente des Eingabevektors in Richtung des Extrema aktualisiert wird.
Aus diesem Grund werden die Parameter aktualisiert, nachdem jeweils nur eine Komponente des Eingabevektors aktualisiert wurde.
Dadurch bedarf das neuronale Netzwerk zur Konvergenz mehr Epochen, muss aber weniger Berechnungen durchführen.
\newline
\newline
(S)GD mit Momentum versucht zu vermeiden, dass lokale Extrema gefunden werden anstatt globale Extrema, indem Momentum aus
vorherigen Gradienten beibehalten wird, um aus lokalen Extrema wieder raus zu finden.
\begin{align}
    \label{formular:sgd_momentum}
    \textbf{v}_{-1} = \textbf{0}, \hspace{0.6cm} \textbf{v}_k = \textbf{v}_{k-1}\gamma +
    \bigtriangledown f(\textbf{x}_k), \hspace{0.6cm} \textbf{x}_{k+1} = \textbf{x}_k - \textbf{v}_k\eta
\end{align}
Gleichung \ref{formular:sgd_momentum} zeigt die iterative Berechnung.
Zur Berechnung wird ein Hilfsvektor $\textbf{v}$ verwendet, welcher das Momentum vergangener Gradienten darstellt.
In jeder Iteration fließt ein Anteil $\gamma$, typischerweise $\gamma=0.9$, von dem Hilfsvektor in die Berechnung der neuen Eingabeparameter ein.
Der Unterschied zum GD (\ref{formular:gd_multi_dim}) ist der Anteil vergangener Gradienten.
\newline
\newline
RMSprop ist eine Variante von \textit{Adagrad}.
Adagrad passt die Lernrate $\eta$ an, denn typischerweise wird zuerst eine hohe Lernrate benötigt und je näher sich dem Extrema angenähert wird,
sollte diese Lernrate sinken.
\begin{align}
    \label{formular:adagrad}
    \textbf{g}_k = \bigtriangledown C_{j_k}(\textbf{x}_k), \hspace{0.6cm}
    \textbf{w}_k = \textbf{w}_{k-1} + \textbf{g}_k^2, \hspace{0.6cm}
    \textbf{x}_{k+1} = \textbf{x}_k - \textbf{g}_k \circ \frac{\eta}{\sqrt{\textbf{w}_k + \epsilon}}
\end{align}
Gleichung \ref{formular:adagrad} zeigt, wie sich iterativ die Lernrate antiproportional
zur kummulierten Norm der Gradienten der Kostenfunktion verringert.
Dabei wird für $\epsilon$ eine kleine Zahl gewählt, um Teilen durch 0 zu vermeiden aber keinen signifikanten Einfluss auf die Berechnung zu haben.
\newline
\newline
Das Problem an Adagrad ist, dass die Lernrate zu schnell gegen 0 konvergieren kann, wodurch das Zielextrema nicht erreicht wird.
RMSprop (\ref{formular:rmsprop}) löst dieses Problem, indem in jeder Iteration ein Zerfallsfaktor $\gamma < 1$ auf den Hilfsvektor $\textbf{w}$ angewendet wird
und Anteilweise das Hadamard-Produkt des Gradienten der Kostenfunktion addiert wird.
\begin{align}
    \label{formular:rmsprop}
    \textbf{w}_{-1} = \textbf{0}, \hspace{0.6cm}
    \textbf{g}_k = \bigtriangledown C_{j_k}(\textbf{x}_k), \hspace{0.6cm}
    \textbf{w}_k = \textbf{w}_{k-1}\gamma + \textbf{g}_k^2 (1-\gamma), \hspace{0.6cm}
    \textbf{x}_{k+1} = \textbf{x}_k - \textbf{g}_k \circ \frac{\eta}{\sqrt{\textbf{w}_k + \epsilon}}
\end{align}
Gleichung \ref{formular:adam} zeigt, wie Adam RMSprop und SGD mit Momentum vereint, wobei $\gamma_1 < \gamma_2 < 1$.
Adam nutzt zwei Hilfsvektoren $\textbf{v}$ und $\textbf{w}$, die mit einer Zerfallsrate wachsen und beim Lernen
sowohl Momentum nutzt, um lokale Extrema zu überbrücken, und passt die Lernrate im Laufe des Trainingsprozesses an.
\begin{align}
    \label{formular:adam}
    \textbf{g}_k = \bigtriangledown C_{j_k}(\textbf{x}_k), \hspace{0.6cm}
    \textbf{v}_k = \textbf{v}_{k-1}\gamma_1 + \textbf{g}_k (1-\gamma_1), \hspace{0.6cm} \nonumber\\
    \textbf{w}_k = \textbf{w}_{k-1}\gamma_2 + \textbf{g}_k^2 (1-\gamma_2), \hspace{0.6cm}
    \textbf{x}_{k+1} = \textbf{x}_k - \textbf{v}_k \circ \frac{\eta}{\sqrt{\textbf{w}_k + \epsilon}}
\end{align}

\section{Aktivierungsfunktionen}
Die Aktivierungsfunktion trennt die einzelnen Schichten von einander, indem sie nicht-linearität einführt (TODO: Quelle).
Aktivierungsfunktion sollten kontinuierlich und differenzierbar sein.
Dies ist wichtig für den \textit{Backpropagation}-Prozess beim Trainieren.
Sie unterscheiden sich in ihren Eigenschaften und Berechnungskosten, was eine besondere Rolle für Mikrocontroller spielt.
Es gibt viele verschiedene Aktivierungsfunktionen, eingeteilt in Familien.
\newline
\newline
In der \textit{Heaviside}-Familie sind die Funktionen \textit{Heaviside}, \textit{modifizierte Heaviside} und die \textit{Logistik} enthalten.
Die Heaviside-Funktion, oder auch Stufenfunktion, ist die Aktivierungsfunktion des biologischen Modells.
Sie ist aber nicht kontinuierlich bei 0 und damit nicht differenzierbar.
Dies stellt ein Problem für neuronale Netze dar, da einerseits sie einerseits unsymmetrisch ist und andererseits die Information über die Distanz zur Entscheidungsgrenze verloren geht.
Die modifizierte Heavisde-Funktion löst das erste Problem, indem 0 der Wert $\frac{1}{2}$ zugeordnet wird.
Das zweite Problem kann durch \textit{sigmoidal} Funktionen gelöst werden.
Eine Variante ist die Logistikfunktion, welche in der frühen Geschichte der neuronalen Netzwerke verwendet wurde.
Sie ist kontinuierlich und differenzierbar. Der Wert der Ableitung ist in der Rechweite $[0, \frac{1}{4}]$.
Dadurch ist sie ungeeignet für tiefe neuronale Netzwerke, da dadurch der Gradient bereits nach wenigen Schichten gegen 0 geht.
Eine Generalisierung der Logistikfunktion ist die \textit{SoftMax}-Funktion oder normalisierte Exponentialfunktion.
Diese wird häufig in der Ausgabeschicht, da ihre Ausgabewerte in der Summe 1 ergeben und sie aus diesem Grund als Wahrscheinlichkeit für jede Klasse betrachtet werden können.
\newline
\newline
Zur \textit{ReLU}-Familie gehört die ReLU-Funktion und ihre Varianten, sowie die \textit{SoftPlus}- und \textit{Swish}-Funktion.
ReLU steht für \glqq\textit{rectified linear function}\grqq\ und wird häufig in modernen neuronalen Netzwerken verwendet.
Sie ist nicht differenzierbar bei 0 und die Ableitung für negative Eingaben ist 0.
Dafür ist die Ableitung der Funktion ansonsten 1, was sehr gut für den Backpropagation-Prozess ist, da dadurch der Gradient unverändert ist.
Zudem ist sie sehr leicht zu berechnen.
Varianten sind \textit{leaky ReLU} und \textit{ELU (exponential linear unit)} welche versuchen das Problem bei 0 zu lösen.
\textit{SoftPlus} ist analytisch, dafür aber aufwendiger zu berechnen im Vergleich zu ReLU.
Eine weitere Variante ist \textit{Swish}. Sie ist analytisch aber nicht monoton.
Im Vergleich zu ReLU ist sie aufwendig zu berechnen.
Ihre Autoren behaupten aber, dass dadurch bessere Ergebnisse erzielt werden können, ohne andere Parameter zu ändern.
\newline
\newline
Daneben gibt es noch die \textit{Sign}-Familie und die \textit{Abs}-Familie, die in dieser Arbeit nicht verwendet werden (TODO: Quelle).

\section{Ressourcenbedarf auf dem Mirkocontroller}
\begin{itemize}
    \item Energieverbrauch
    \item Speicherverbrauch
    \item RAM verbrauch
    \item Siehe Kubik und Co.
\end{itemize}