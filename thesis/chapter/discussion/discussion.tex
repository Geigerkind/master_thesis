\chapter{Diskussion}
\label{chapter:discussion}
Ein Großteil dieser Arbeit ist die Generierung von Sensordaten.
Dazu wurde der Ansatz von Mian aufgegriffen, wodurch verschiedene Routen in CoppeliaSim simuliert wurden.
Der Nachteil dieses Ansatzes ist die schlechte Skalierbarkeit, wenn es um die Untersuchung von Pfaden und Standorten geht.
Um weitere Pfade und Standorte zu untersuchen, mussten entweder komplexere Routen in CoppeliaSim erstellt werden,
Routen synthetisch kombiniert werden oder Routen unabhängig von einander trainiert werden.
\newline
\newline
Der erste Ansatz ist sehr aufwändig und der zweite Ansatz unterscheidet sich nicht stark von dem dritten Ansatz,
da die Routen nur an einem Punkt kombiniert werden.
Ein besserer Ansatz wäre es gewesen, wenn man lediglich abgeschlossene Teilstücke simuliert hätte,
z.~B. eine Kurve oder eine Gerade nach links laufend.
Jedes dieser Teilstücke hätte eine feste Länge und könnte transformiert werden in sowohl der Länge, als auch den aufgenommen Sensordaten.
Durch geschickte Kombination, könnten dann beliebig komplexe Routen mit beliebig vielen Pfaden und Standorten generiert werden,
was die Untersuchung erheblich erleichtert hätte.
Zudem könnten genauere Aussagen über die Skalierung der Klassifizierungsgenauigkeit mit der Standortkomplexität getroffen werden können,
da die Standortkomplexität systematisch erhöht werden könnte.
\newline
\newline
Die Entscheidungswälder könnten gezielter trainiert werden, um die Klassifizierungsgenauigkeit zu erhöhen und die Robustheit zu verbessern.
Zuerst wird ein Entscheidungswald mit allen Features trainiert.
Aus diesem Entscheidungswald wird die Signifikanz der einzelnen Features geschlossen.
Auf Basis dessen werden gezielt Teilmengen aus der Feature-Menge extrahiert, womit orthogonale Entscheidungsbäume trainiert werden.
Anschließend werden diese Entscheidungsbäume zu einem Entscheidungswald kombiniert.
\newpage
Für das FFNN wurde für die vorherigen Standorte zwei Features verwendet, die alle Standorte zwischen 0 und 1 kodiert haben.
Dies hat dazu geführt, dass FFNNs mit steigender Standortkomplexität schlechtere Klassifizierungsergebnisse erzielt haben als Entscheidungswälder.
Besser hätten die vorherigen Standorte kategorisch kodiert werden sollen.
Dadurch würde die Eingabeschicht des FFNNs zwar stark wachsen, aber das Problem möglicherweise eliminiert werden.
\newline
\newline
Um die Robustheit gegenüber ausgefallenen Sensoren zu erhöhen wurde synthetisch die Trainingsmenge mit Datensätzen ergänzt, die ausgefallen Sensoren simulieren.
KNN bieten die Methode \textit{DropConnect} an, welche die Gewichte einzelner Kanten zu einer bestimmten Wahrscheinlichkeit nullt.
Ein FFNN mit DropConnect nach der Eingabeschicht hätte effizienter trainiert werden können unter gleichen Anforderungen zur Robustheit,
da die synthetischen Trainingsdaten nicht benötigt werden würden.
\newline
\newline
Beim Training der ML-Modelle ist eine Aufwärmphase vorgesehen, damit die ML-Modelle eine Chance haben die nachfolgenden Partitionen der Trainingsmenge
zu einer hohen Wahrscheinlichkeit zu bestimmen.
Möglicherweise wurden in dieser Arbeit zu viele Aufwärmzyklen verwendet, wodurch eine hohe Abhängigkeit zum vorherigen Standort im Vergleich zu anderen Features beobachtet werden konnte.

