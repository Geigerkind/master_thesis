\section{Sensorbasierter Orientierungssinn mit FFNN}
Dieser Arbeit ging die Arbeit von Mian voran, der sich zum gleichen Thema mit FFNN auseinander gesetzt hat \cite{naveedThesis}.
Mian nutzte den Simulator CoppeliaSim, um Daten von verschieden komplexen Routen zu generieren.
Die Routen unterschieden sich dabei in der Anzahl verschiedener Orte und Pfade die für einen Zyklus einer Route verwendet werden können.
Die aufgenommenen Daten enthalten Sensorwerte für Beschleunigung, Gyroskop, Licht und Beschriftungen für die Standorte.
Dabei werden als Standorte die Teilstücke der Routen bezeichnet aus denen die Route zusammengesetzt ist.
\newline
\newline
Mian entschied sich die aufgenommen Sensordaten vorzuverarbeiten.
Zunächst werden die Sensoren für fünf Stichproben über den Median geglättet.
Aus den resultierenden Sensorwerten wird die Veränderung zum vorherigen Sensorwert für jeden Sensor ermittelt.
Für jeden Sensor wird als Feature der Betrag dieser Differenz verwendet.
Um Muster aus einer Folge von Feature-Mengen zu inferieren hat Mian ein Datenfenster eingeführt, über das
hintereinander liegende Feature-Mengen zu einer Feature-Menge konkatiniert werden.
Zudem werden die zuletzt besuchten Standorte in Form einer exponentiell fallenenden Funktion über die Zeit als weitere Features hinzugefügt.
\newline
\newline
Mit dieser Eingabe trainierte Mian ein FFNN mit einer Rückwärtskante (FBNN) von der Ausgabe- zur Eingabeschicht,
um die zuletzt bestimmten Standorte als Features nutzen zu können.
Die Rückwärtskante wurde im Training simuliert, indem die Trainingsdaten in zwei Teilmengen partitioniert wurden.
Mit der ersten Teilmenge wurde das FFNN mit korrekt beschrifteten Trainingsdaten trainiert.
Das trainierte FFNN wurde dann genutzt, um die Standorte der zweiten Teilmenge zu bestimmen.
Daraufhin wurde das FFNN mit der zweiten Teilmenge trainiert, bevor es auf einer Testmenge validiert wurde.
\newline
\newline
Mian unterscheidet vier Modellarchitekturen: FFNN, FBNN, WFFNN (FFNN mit Datenfenster) und WFBNN (FBNN mit Datenfenster).
Er stellte fest, dass das FFNN nicht in der Lage war verschiedene Standorte zu unterscheiden,
unabhängig von der Anzahl der verdeckten Schichten und dessen Anzahl von Neuronen.
\newline
\newline
Das FBNN hingegen konnte bei einer Route mit einem Pfad und sechs Standorten Testgenauigkeiten von bis zu 86,73\% erzielen.
Allerdings bedarf es dafür zwei verdeckte Schichten mit jeweils 64 Neuronen.
Mit weniger Schichten oder Neuronen wurden deutlich schlechtere Ergebnisse erzielt.
Bei mehr Pfaden und Standorten wurden ebenfalls schlechtere Ergebnisse erzielt.
\newline
\newline
Mit der Einführung eines Datenfensters (WFFNN und WFBNN) hat sich die Klassifizierungsgenauigkeit signifikant erhöht.
Ein WFFNN mit zwei verdeckten Schichten mit jeweils 16 Neuronen und einem Datenfenster von 25 konnte eine Testgenauigkeit von 93,31\%
bei einem Pfad und sechs Standorten erreichen.
Durch das Vergrößern des Datenfensters und mehr Neuronen pro verdeckte Schicht konnte Mian die Klassifizierungsgenauigkeit auf bis zu 95,57\% erhöhen.
Das WFBNN hat keine signifikante Änderung zum WFFNN gezeigt.
\newline
\newline
Mian stellte fest, dass sich die Klassifizierungsgenauigkeiten weiter verbessern ließen,
wenn er eine Lichtquelle an Standorten setzt, wo sich die neuronalen Netze unsicher sind.
Allerdings würden Fehler durch den Sensor oder Veränderungen der Lichtverhältnisse
einen größeren Einfluss auf die Klassifizierungsgenauigkeit des Modells haben.
\newline
\newline
Mian konkludierte, dass ein Kompromiss zwischen Klassifizierungsgenauigkeit und Modellgröße geschlossen werden müsste,
da die Modellgröße und Klassifizierungsgenauigkeit proportional mit der Anzahl der verdeckten Schichten und Neuronen,
sowie der Datenfenstergröße zusammenhinge.
