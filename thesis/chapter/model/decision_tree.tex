\section{Entscheidungswald}
\label{sec:model_dt}
Entscheidungsbaum basierte Klassifizierer sind sehr effizient und können trotzdem hohe Klassifizierungsgenauigkeiten bei hohen Fehlertoleranzen erreichen \cite{dymelThesis}.
Entscheidungswälder erhöhen die Klassifizierungsgenauigkeit während die Varianz reduziert wird, dafür wird aber der Speicherbedarf mit jedem Baum linear erhöht.
Der Klassifizierer soll zukünftig auf einem Mikrocontroller ausgeführt werden, d. h. die Größe des Entscheidungswaldes ist durch den Programmspeicher des Mikrocontrollers limitiert.
zum Zeitpunkt, zu der diese Arbeit verfasst wird, sind die Limitierungen des Mikrocontrollers noch nicht bekannt.
Für gewöhnlich ist der Programmspeicher aber auf wenige Kilobyte beschränkt \cite{dymelThesis}.
\newline
\newline
Als Ensemble-Methode wird der \textit{RandomForest} benutzt, da dieser Entscheidungsbäume auf Basis von zufälligen Teilmengen der Feature-Menge konstruiert.
Dadurch ist eine erhöhte Toleranz gegenüber Fehlern, wie fehlerhafte Sensorwerte oder anderen Features zu erwarten.
\newline
\newline
Um den Einfluss von verschiedenen Wald- und Baumgrößen auf die Klassifizierungsgenauigkeit hin zu untersuchen, werden verschiedene Größen
trainiert und auf den Testmengen evaluiert. Trotzdem wurden Dimensionen in einem Bereich gewählt, die für einen Mikrocontroller realistisch sind.
Es wurden jeweils Bäume und Wälder der Größe 8, 16, 32, und 64 untersucht.