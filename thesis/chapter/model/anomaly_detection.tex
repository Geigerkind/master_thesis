\newpage
\section{Anomalieerkennung}
Als Anomalieerkennung wird in dieser Arbeit das Problem bezeichnet, zu erkennen, dass die Sensorenbox sich an einem
unbekannten Standort oder auf einem unbekannten Pfad befindet.
Abbildung \ref{fig:model_idea} zeigt, dass die Anomalieerkennung ein eigener Schritt bei der Evaluierung der Sensordaten ist.
Die Eingabe sind Features, die auf historischen Daten und dem momentanen Standort basieren.
\newline
\newline
Es wird ein zweites ML-Modell trainiert, anstatt dem ML-Modell zur Standorterkennung einen \textit{Anomaliestandort} lernen zu lassen.
Dies ist begründet auf der Schwierigkeit Trainingsdaten für Anomalien basierend auf den Sensordaten zu entwickeln,
da es unendlich viele Szenarien geben könnte, die als Anomalie zu bezeichnen sind.
Stattdessen werden Features genutzt, die eine Abweichung von der Normalität ausdrücken,
d. h. das ML-Modell lernt nicht explizite Anomaliepfade, sondern das Verhalten des Standortklassifizierungsmodells einzuordnen.
\newline
\newline
Dafür werden analog zu Kapitel \ref{sec:model_dt} und \ref{sec:model_ffnn} Entscheidungswälder und FFNN trainiert.
Allerdings bedarf dieses Modell keine Rückwärtskante und das FFNN kann für binäre Klassifizierung vereinfacht werden.
Die letzte Schicht des FFNN hat nur ein Neuron und nutzt die Sigmoid-Funktion, anstatt der SoftMax-Funktion.
Außerdem wird für die Kostenfunktion \textit{binäre Crossentropy} verwendet, anstatt kategorische Crossentropy.
Binäre Crossentropy bedarf keine kategorische Enkodierung im Gegensatz zur kategorischen Crossentropy.
\newline
\newline
Die ML-Modelle zur Anomalieerkennung können seperat von den ML-Modellen zur Standorterkennung trainiert werden.
Sie werden im Gegensatz zu den ML-Modellen zur Standorterkennung nur einmalig trainiert mit vorbereiteten Trainingsdaten.
Die Trainingsdaten werden aus den Anomaliedatenmengen und Datenmengen für die verschieden Routen generiert.
Dafür werden die Klassifizierungsergebnisse auf diesen Datenmengen von den zuvor trainierten ML-Modellen zur Standorterkennung genutzt.
Daraus werden beschriftete Features extrahiert, die in Kapitel \ref{sec:data_anomalie} detailiert erläutert werden.
\newpage
Alternativ können nicht ML-Modelle als Vergleichsmodelle genutzt werden.
Die trivialen Modelle sind das \textit{Coin-Toss}-, \textit{immer Falsch}- und \textit{immer Wahr}-Modell.
Ein komplexeres Modell nutzt die Topologie des Systems aus, um eine Anamolie zu indizieren, wenn die Sensorenbox nicht dem Pfad folgt.
In einer lockereren Variante könnte nur erwartet werden, dass einem Pfad kontinuierlich gefolgt wird,
sodass übersprungende Standorte nicht dauerhaft eine Anomalie indizieren.
Abbildung \ref{lst:topology_anomaly_detection} skizziert dieses Modell.
Wenn der Standort und der vorherige Standort nicht der unbekannte Standort ist und
der vorherige Standort ungleich dem erwarteten Standort ist, dann wird ein Alarm ausgelöst.
Dieser Alarm indiziert für eine konstante Dauer, dass eine Anomalie vorliegt.
Dies ist motiviert aus dem Zusammenhang, dass wenn eine Anomalie vorliegt, es wahrscheinlich ist, dass sie kurz danach immernoch vorliegt.
\begin{lstlisting}[label=lst:topology_anomaly_detection, caption={Skizze des Modells zur Anamolieerkennung auf Basis der Topologie.}]
if standort > 0 and vorheriger_standort > 0 and topologie[standort].vorheriger_standort != vorheriger_standort:
    alarm_zaehler = 0

if alarm_dauer > alarm_zaehler:
    alarm_zaehler++
    return true
return false
\end{lstlisting}
