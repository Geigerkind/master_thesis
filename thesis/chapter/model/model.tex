\chapter{Machine Learning Modelle}
In dieser Arbeit wird die Device-Based Indoor-Lokalisation auf Basis von Sensorwerten untersucht.
Der Ansatz ist inspiriert von dem Orientierungssinn von Menschen und Tieren.
Dabei werden diskrete Standorte unterschieden sowie, ob eine Anomalie entdeckt wurde,
d. h. ob das Modell sich an einem unbekannten Standort oder auf einem unbekannten Pfad befindet.
\newline
\newline
Abbildung \ref{fig:model_idea} zeigt die Architektur des verfolgten Ansatzes.
Zunächst werden aus den Sensorwerten Features extrahiert.
Die resultierende Feature-Menge wird dann vom ML-Modell genutzt, um den Standort zu klassifizieren.
Zuletzt wird auf Basis historischer Daten und dem Klassifizierungsergebnis von einem weiteren ML-Modell zur Anomalieerkennung bestimmt, ob eine Anomalie vorliegt.
\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{images/model_idea.png}
    \caption{Architektur des verfolgten Ansatzes.}
    \label{fig:model_idea}
\end{figure}
\newline
Mian verwendete eine ähnliche Architektur \cite{naveedThesis}.
Sein (W)FBNN zur Standortbestimmung hatte ebenfalls eine Rückwärtskante, um die zuletzt erkannten Standorte als Features zu verwenden.
Die gestrichelte Linie signalisiert, dass, ähnlich zu Mian, auch ML-Modelle ohne Rückwärtskante evaluiert werden.
In dieser Arbeit wird zusätzlich versucht Anomalien zu erkennen.
Dafür wird ein weiteres ML-Modell verwendet, welches aus dem Klassifizierungsverhalten des ML-Modells zur Standortbestimmung schließt, ob eine Anomalie vorliegt.
Dies motiviert die Erweiterung, um eine weitere Phase zur Feature-Extrahierung aus den zuletzt erkannten Standorten,
sowie einer Phase zur Evaluierung des ML-Modells zur Anomalieerkennung aus der resultierenden Feature-Menge.
\newpage
Die Anomalieerkennung interpretiert somit das Standortbestimmungsverhalten des vorangestellen ML-Modells zur Standortbestimmung,
weshalb sowohl der Standort als auch die Einschätzung der Anomalie als Ergebnis zurückgegeben werden.
\newline
\newline
In dieser Arbeit werden Entscheidungsbaum basierte Klassifizierer mit FFNNs verglichen, insbesondere den von Mian verwendeten Ansatz des FBNNs.
Entscheidungsbäume sind deutlich effizienter in der Ausführungszeit als FFNNs \cite{dymelThesis},
allerdings sind sie in ihrer Generalisierungsfähigkeit durch die berechneten Features begrenzt,
wohingegen FFNNs komplexe Features selbst erlernen können \cite{seide2011feature}.

\input{chapter/model/location_encoding}
\input{chapter/model/decision_tree}
\input{chapter/model/ffnn}
\input{chapter/model/training}
\input{chapter/model/anomaly_detection}

